{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09afc391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from torch_geometric.nn import (\n",
    "    GCNConv, GATv2Conv, SAGEConv, GINEConv,\n",
    "    NNConv, PNAConv, global_mean_pool\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "LABEL_MAP = {\"Benign\": 0, \"InSitu\": 1, \"Invasive\": 2, \"Normal\": 3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f619367",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, kind, in_ch, edge_ch, hidden, out):\n",
    "        super().__init__()\n",
    "        self.kind = kind\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        if kind == \"GCN\":\n",
    "            self.conv1 = GCNConv(in_ch, hidden)\n",
    "            self.conv2 = GCNConv(hidden, hidden)\n",
    "        elif kind == \"GAT\":\n",
    "            self.conv1 = GATv2Conv(in_ch, hidden // 4, heads=4)\n",
    "            self.conv2 = GATv2Conv(hidden, hidden, heads=1, concat=False)\n",
    "        elif kind == \"SAGE\":\n",
    "            self.conv1 = SAGEConv(in_ch, hidden)\n",
    "            self.conv2 = SAGEConv(hidden, hidden)\n",
    "        elif kind == \"GIN\":\n",
    "            nn1 = nn.Sequential(nn.Linear(in_ch, hidden), nn.ReLU(), nn.Linear(hidden, hidden))\n",
    "            nn2 = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(), nn.Linear(hidden, hidden))\n",
    "            self.conv1 = GINEConv(nn1, edge_dim=edge_ch)\n",
    "            self.conv2 = GINEConv(nn2, edge_dim=edge_ch)\n",
    "        elif kind == \"MPNN\":\n",
    "            lin = nn.Linear(edge_ch, in_ch * hidden)\n",
    "            self.conv1 = NNConv(in_ch, hidden, lin)\n",
    "            self.conv2 = NNConv(hidden, hidden, lin)\n",
    "        elif kind == \"PNA\":\n",
    "            self.conv1 = PNAConv(in_ch, hidden,\n",
    "                aggregators=[\"mean\", \"max\", \"min\", \"std\"],\n",
    "                scalers=[\"identity\", \"amplification\", \"attenuation\"],\n",
    "                deg=None  # TODO: Set degree histogram if needed\n",
    "            )\n",
    "            self.conv2 = PNAConv(hidden, hidden,\n",
    "                aggregators=[\"mean\", \"max\", \"min\", \"std\"],\n",
    "                scalers=[\"identity\", \"amplification\", \"attenuation\"],\n",
    "                deg=None\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown kind {kind}\")\n",
    "\n",
    "        self.skip1 = nn.Linear(in_ch, hidden) if in_ch != hidden else nn.Identity()\n",
    "        self.skip2 = nn.Identity()\n",
    "        self.bn1 = nn.BatchNorm1d(hidden)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden)\n",
    "        self.lin = nn.Linear(hidden, out)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        if self.kind in [\"GIN\", \"MPNN\"]:\n",
    "            h = self.conv1(x, edge_index, edge_attr)\n",
    "        else:\n",
    "            h = self.conv1(x, edge_index)\n",
    "\n",
    "        h = self.bn1(h)\n",
    "        h = F.relu(h + self.skip1(x))\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        if self.kind in [\"GIN\", \"MPNN\"]:\n",
    "            h2 = self.conv2(h, edge_index, edge_attr)\n",
    "        else:\n",
    "            h2 = self.conv2(h, edge_index)\n",
    "\n",
    "        h2 = self.bn2(h2)\n",
    "        h2 = F.relu(h2 + self.skip2(h))\n",
    "        h2 = self.dropout(h2)\n",
    "\n",
    "        hg = global_mean_pool(h2, batch)\n",
    "        return self.lin(hg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        if isinstance(out, tuple): out = out[0]\n",
    "        loss = F.cross_entropy(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            if isinstance(out, tuple): out = out[0]\n",
    "            pred = out.argmax(dim=1)\n",
    "        all_preds += pred.cpu().tolist()\n",
    "        all_labels += batch.y.cpu().tolist()\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(classification_report(all_labels, all_preds, target_names=LABEL_MAP.keys(), digits=3))\n",
    "    return acc, confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "def plot_cm(cm, classes):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9dd580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "\n",
    "# Define your color mappings\n",
    "NODE_COLORS = {\n",
    "    0: 'blue',\n",
    "    1: 'yellow',\n",
    "    2: 'red',\n",
    "    3: 'black',\n",
    "    4: 'green',\n",
    "    5: 'aqua'\n",
    "}\n",
    "DEFAULT_NODE_COLOR = \"gray\"\n",
    "EDGE_COLOR = \"black\"\n",
    "EDGE_WIDTH_SCALE = 1.5\n",
    "\n",
    "def visualize_original_and_subgraph(image_path, graphml_path, subgraph_pt_path):\n",
    "    # Load image\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    base = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "    # Load original graph\n",
    "    G = nx.read_graphml(graphml_path)\n",
    "    pos_full = {n: (float(G.nodes[n]['x']), float(G.nodes[n]['y'])) for n in G.nodes}\n",
    "    node_colors_full = [NODE_COLORS.get(int(G.nodes[n].get('type', 0)), DEFAULT_NODE_COLOR) for n in G.nodes]\n",
    "    edge_list_full = list(G.edges())\n",
    "    weights_full = [float(G.edges[e]['weight']) for e in edge_list_full]\n",
    "    widths_full = [w * EDGE_WIDTH_SCALE for w in weights_full]\n",
    "\n",
    "    # Load subgraph (PyG Data)\n",
    "    data = torch.load(subgraph_pt_path)\n",
    "    x = data.x.cpu().numpy()\n",
    "    edge_index = data.edge_index.cpu().numpy()\n",
    "\n",
    "    # Convert edge index to pairs\n",
    "    edge_list_sub = [(int(u), int(v)) for u, v in edge_index.T]\n",
    "\n",
    "    # Position and color for subgraph\n",
    "    pos_sub = {i: (x[i][0], x[i][1]) for i in range(x.shape[0])}\n",
    "    node_colors_sub = [NODE_COLORS.get(int(x[i][2]), DEFAULT_NODE_COLOR) for i in range(x.shape[0])]\n",
    "    widths_sub = [1.5 for _ in edge_list_sub]  # Default width\n",
    "\n",
    "    # Build subgraph as NetworkX graph\n",
    "    G_sub = nx.Graph()\n",
    "    G_sub.add_nodes_from(pos_sub.keys())\n",
    "    G_sub.add_edges_from(edge_list_sub)\n",
    "\n",
    "    # Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "    # Original graph on image\n",
    "    ax1.imshow(img)\n",
    "    nx.draw_networkx_edges(G, pos_full, ax=ax1, edgelist=edge_list_full, edge_color=EDGE_COLOR, width=widths_full)\n",
    "    nx.draw_networkx_nodes(G, pos_full, ax=ax1, node_color=node_colors_full, node_size=30)\n",
    "    ax1.set_title(f\"Original Graph: {base}\")\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # Subgraph on same image\n",
    "    ax2.imshow(img)\n",
    "    nx.draw_networkx_edges(G_sub, pos_sub, ax=ax2, edge_color=EDGE_COLOR, width=widths_sub)\n",
    "    nx.draw_networkx_nodes(G_sub, pos_sub, ax=ax2, node_color=node_colors_sub, node_size=50)\n",
    "    ax2.set_title(f\"Subgraph Overlay: {os.path.basename(subgraph_pt_path)}\")\n",
    "    ax2.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5d2b75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Full Graph:\n",
      "Data(x=[1504], edge_index=[2, 4487], edge_attr=[4487, 1], y=[1504], original_node_indices=[1504], type=[1504], area=[1504], perimeter=[1504], eccentricity=[1504], solidity=[1504], circularity=[1504])\n",
      "\n",
      "\n",
      "SubGraph:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1269806/1868949542.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G = torch.load('graphs_new_pannuke/Invasive/1.pt')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "# Load .graphml using networkx\n",
    "G = torch.load('graphs_new_pannuke/Invasive/1.pt')\n",
    "\n",
    "# # Load subgraph (.pt) as usual\n",
    "# data_subgraphs = torch.load('subgraphs_pannuke_s20/b017_sg240.pt')\n",
    "\n",
    "# Print summaries\n",
    "print(\"Original Full Graph:\")\n",
    "print(G)\n",
    "print(\"\\n\\nSubGraph:\")\n",
    "# print(data_subgraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3108b929",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visualize_original_and_subgraph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mvisualize_original_and_subgraph\u001b[49m(\n\u001b[1;32m      3\u001b[0m         image_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/data/Photos/Benign/b017.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m         graphml_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraphs_new_pannuke/Benign/b017.graphml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m         subgraph_pt_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubgraphs_pannuke_s20/b017_sg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'visualize_original_and_subgraph' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(1,100,10):\n",
    "    visualize_original_and_subgraph(\n",
    "        image_path=\"dataset/data/Photos/Benign/b017.tif\",\n",
    "        graphml_path=\"graphs_new_pannuke/Benign/b017.graphml\",\n",
    "        subgraph_pt_path=f\"subgraphs_pannuke_s20/b017_sg{i}.pt\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bafbe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "import torch\n",
    "\n",
    "class SubgraphDatasetFromSavedFiles(InMemoryDataset):\n",
    "    def __init__(self, subgraph_metadata_csv, transform=None, pre_transform=None):\n",
    "        super(SubgraphDatasetFromSavedFiles, self).__init__('.', transform, pre_transform)\n",
    "        self.meta_df = pd.read_csv(subgraph_metadata_csv)\n",
    "        self.data_list = []\n",
    "\n",
    "        for _, row in self.meta_df.iterrows():\n",
    "            data = torch.load(row['subgraph_path'])\n",
    "            self.data_list.append(data)\n",
    "\n",
    "        self.data, self.slices = self.collate(self.data_list)\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [data.y.item() for data in self.data_list]\n",
    "# Load the subgraph datasets\n",
    "train_ds = SubgraphDatasetFromSavedFiles(\"train_meta.csv\")\n",
    "test_ds  = SubgraphDatasetFromSavedFiles(\"test_meta.csv\")\n",
    "\n",
    "# Data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_ds = SubgraphDatasetFromSavedFiles(\"train_meta.csv\")\n",
    "test_ds = SubgraphDatasetFromSavedFiles(\"test_meta.csv\")\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "hist = {}\n",
    "results = {}\n",
    "\n",
    "# for kind in [\"GCN\", \"GAT\", \"SAGE\", \"GIN\", \"MPNN\"]:\n",
    "#     model = GNN(kind,\n",
    "#                 in_ch=train_ds[0].x.size(1),\n",
    "#                 edge_ch=train_ds[0].edge_attr.size(1) if train_ds[0].edge_attr is not None else 0,\n",
    "#                 hidden=64, out=4).to(device)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "\n",
    "#     losses, accs = [], []\n",
    "#     for epoch in range(1, 31):\n",
    "#         loss = train_epoch(model, train_dl, optimizer, device)\n",
    "#         acc, _ = eval_model(model, test_dl, device)\n",
    "#         losses.append(loss)\n",
    "#         accs.append(acc)\n",
    "\n",
    "#     hist[kind] = (losses, accs)\n",
    "#     results[kind] = accs[-1]\n",
    "#     torch.save(model.state_dict(), f\"models/{kind.lower()}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d87d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for kind in [\"GCN\", \"GAT\", \"SAGE\", \"GIN\", \"MPNN\"]:\n",
    "    model = GNN(kind,\n",
    "                in_ch=train_ds[0].x.size(1),\n",
    "                edge_ch=train_ds[0].edge_attr.size(1) if train_ds[0].edge_attr is not None else 0,\n",
    "                hidden=64, out=4).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "\n",
    "    losses, accs = [], []\n",
    "    for epoch in range(1, 31):\n",
    "        loss = train_epoch(model, train_dl, optimizer, device)\n",
    "        acc, _ = eval_model(model, test_dl, device)\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "\n",
    "    hist[kind] = (losses, accs)\n",
    "    results[kind] = accs[-1]\n",
    "    torch.save(model.state_dict(), f\"models/{kind.lower()}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6784de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "for k, (ls, _) in hist.items():\n",
    "    plt.plot(ls, label=f\"{k} loss\")\n",
    "plt.legend(); plt.title(\"Training Loss\"); plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "for k, (_, acc) in hist.items():\n",
    "    plt.plot(acc, label=f\"{k} acc\")\n",
    "plt.legend(); plt.title(\"Validation Accuracy\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21868e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell: Training & Saving (fixed hist init)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_ds = NucleiGraphDataset(\"train_meta.csv\")\n",
    "test_ds  = NucleiGraphDataset(\"test_meta.csv\")\n",
    "tr_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "te_dl = DataLoader(test_ds, batch_size=16)\n",
    "\n",
    "hist = {}\n",
    "final_acc = {}\n",
    "\n",
    "for kind in [\"GCN\",\"GAT\",\"SAGE\",\"GIN\",\"MPNN\",\"PNA\"]:\n",
    "    model = GNN(kind,\n",
    "                in_ch=train_ds[0].x.size(1),\n",
    "                edge_ch=train_ds[0].edge_attr.size(1),\n",
    "                hidden=64, out=4).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "\n",
    "    losses, accs = [], []\n",
    "    for epoch in range(1, 31):\n",
    "        l = train_epoch(model, tr_dl, opt, device)\n",
    "        a, _ = eval_model(model, te_dl, device)\n",
    "        losses.append(l)\n",
    "        accs.append(a)\n",
    "\n",
    "    hist[kind] = (losses, accs)           # now works\n",
    "    final_acc[kind] = accs[-1]\n",
    "    torch.save(model.state_dict(), f\"models/{kind.lower()}.pth\")\n",
    "\n",
    "results = {}\n",
    "test_ds = NucleiGraphDataset(\"test_meta.csv\")\n",
    "test_dl = DataLoader(test_ds, batch_size=16)\n",
    "\n",
    "for kind in [\"GCN\",\"GAT\",\"SAGE\",\"GIN\",\"MPNN\",\"PNA\"]:\n",
    "    # load\n",
    "    path = f\"models/{kind.lower()}.pth\"\n",
    "    model = GNN(kind,\n",
    "                in_ch=test_ds[0].x.size(1),\n",
    "                edge_ch=test_ds[0].edge_attr.size(1),\n",
    "                hidden=64, out=4).to(device)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    \n",
    "    # evaluate\n",
    "    acc, cm = eval_model(model, test_dl, device)\n",
    "    print(f\"{kind} Test Accuracy: {acc:.3f}\")\n",
    "    \n",
    "    # confusion matrix\n",
    "    plot_cm(cm, list(LABEL_MAP.keys()))\n",
    "    \n",
    "    results[kind] = acc\n",
    "\n",
    "# summary bar chart\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(results.keys(), results.values())\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Model Comparison\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kind in results:\n",
    "    path = f\"models/{kind.lower()}.pth\"\n",
    "    model = GNN(kind,\n",
    "                in_ch=test_ds[0].x.size(1),\n",
    "                edge_ch=test_ds[0].edge_attr.size(1) if test_ds[0].edge_attr is not None else 0,\n",
    "                hidden=64, out=4).to(device)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "\n",
    "    acc, cm = eval_model(model, test_dl, device)\n",
    "    print(f\"{kind} Test Accuracy: {acc:.3f}\")\n",
    "    plot_cm(cm, list(LABEL_MAP.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673ea30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408ad17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "histographs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
